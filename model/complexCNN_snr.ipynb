{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import seaborn as sns\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from network import create_model, create_dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch是否编译了CUDA: True\n",
      "PyTorch CUDA版本: 12.6\n"
     ]
    }
   ],
   "source": [
    "# 检查PyTorch是否正确编译了CUDA\n",
    "print(f\"PyTorch是否编译了CUDA: {torch.cuda.is_available()}\")\n",
    "print(f\"PyTorch CUDA版本: {torch.version.cuda}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 选择训练方式\n",
    "snr_list = [-10, -5, 0, 5, 10, 15, 20, 25, 30, 35, 40, 45, 50] # 基于信噪比进行训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Y\\AppData\\Local\\Temp\\ipykernel_224448\\2893921692.py:9: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  X_train = df_train.drop('label', axis=1).applymap(lambda x: complex(x)).values\n",
      "C:\\Users\\Y\\AppData\\Local\\Temp\\ipykernel_224448\\2893921692.py:14: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  X_test = df_test.drop('label', axis=1).applymap(lambda x: complex(x)).values\n",
      "C:\\Users\\Y\\AppData\\Local\\Temp\\ipykernel_224448\\2893921692.py:9: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  X_train = df_train.drop('label', axis=1).applymap(lambda x: complex(x)).values\n",
      "C:\\Users\\Y\\AppData\\Local\\Temp\\ipykernel_224448\\2893921692.py:14: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  X_test = df_test.drop('label', axis=1).applymap(lambda x: complex(x)).values\n",
      "C:\\Users\\Y\\AppData\\Local\\Temp\\ipykernel_224448\\2893921692.py:9: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  X_train = df_train.drop('label', axis=1).applymap(lambda x: complex(x)).values\n",
      "C:\\Users\\Y\\AppData\\Local\\Temp\\ipykernel_224448\\2893921692.py:14: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  X_test = df_test.drop('label', axis=1).applymap(lambda x: complex(x)).values\n",
      "C:\\Users\\Y\\AppData\\Local\\Temp\\ipykernel_224448\\2893921692.py:9: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  X_train = df_train.drop('label', axis=1).applymap(lambda x: complex(x)).values\n",
      "C:\\Users\\Y\\AppData\\Local\\Temp\\ipykernel_224448\\2893921692.py:14: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  X_test = df_test.drop('label', axis=1).applymap(lambda x: complex(x)).values\n",
      "C:\\Users\\Y\\AppData\\Local\\Temp\\ipykernel_224448\\2893921692.py:9: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  X_train = df_train.drop('label', axis=1).applymap(lambda x: complex(x)).values\n",
      "C:\\Users\\Y\\AppData\\Local\\Temp\\ipykernel_224448\\2893921692.py:14: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  X_test = df_test.drop('label', axis=1).applymap(lambda x: complex(x)).values\n",
      "C:\\Users\\Y\\AppData\\Local\\Temp\\ipykernel_224448\\2893921692.py:9: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  X_train = df_train.drop('label', axis=1).applymap(lambda x: complex(x)).values\n",
      "C:\\Users\\Y\\AppData\\Local\\Temp\\ipykernel_224448\\2893921692.py:14: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  X_test = df_test.drop('label', axis=1).applymap(lambda x: complex(x)).values\n",
      "C:\\Users\\Y\\AppData\\Local\\Temp\\ipykernel_224448\\2893921692.py:9: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  X_train = df_train.drop('label', axis=1).applymap(lambda x: complex(x)).values\n",
      "C:\\Users\\Y\\AppData\\Local\\Temp\\ipykernel_224448\\2893921692.py:14: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  X_test = df_test.drop('label', axis=1).applymap(lambda x: complex(x)).values\n",
      "C:\\Users\\Y\\AppData\\Local\\Temp\\ipykernel_224448\\2893921692.py:9: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  X_train = df_train.drop('label', axis=1).applymap(lambda x: complex(x)).values\n",
      "C:\\Users\\Y\\AppData\\Local\\Temp\\ipykernel_224448\\2893921692.py:14: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  X_test = df_test.drop('label', axis=1).applymap(lambda x: complex(x)).values\n",
      "C:\\Users\\Y\\AppData\\Local\\Temp\\ipykernel_224448\\2893921692.py:9: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  X_train = df_train.drop('label', axis=1).applymap(lambda x: complex(x)).values\n",
      "C:\\Users\\Y\\AppData\\Local\\Temp\\ipykernel_224448\\2893921692.py:14: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  X_test = df_test.drop('label', axis=1).applymap(lambda x: complex(x)).values\n",
      "C:\\Users\\Y\\AppData\\Local\\Temp\\ipykernel_224448\\2893921692.py:9: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  X_train = df_train.drop('label', axis=1).applymap(lambda x: complex(x)).values\n",
      "C:\\Users\\Y\\AppData\\Local\\Temp\\ipykernel_224448\\2893921692.py:14: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  X_test = df_test.drop('label', axis=1).applymap(lambda x: complex(x)).values\n",
      "C:\\Users\\Y\\AppData\\Local\\Temp\\ipykernel_224448\\2893921692.py:9: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  X_train = df_train.drop('label', axis=1).applymap(lambda x: complex(x)).values\n",
      "C:\\Users\\Y\\AppData\\Local\\Temp\\ipykernel_224448\\2893921692.py:14: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  X_test = df_test.drop('label', axis=1).applymap(lambda x: complex(x)).values\n",
      "C:\\Users\\Y\\AppData\\Local\\Temp\\ipykernel_224448\\2893921692.py:9: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  X_train = df_train.drop('label', axis=1).applymap(lambda x: complex(x)).values\n",
      "C:\\Users\\Y\\AppData\\Local\\Temp\\ipykernel_224448\\2893921692.py:14: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  X_test = df_test.drop('label', axis=1).applymap(lambda x: complex(x)).values\n",
      "C:\\Users\\Y\\AppData\\Local\\Temp\\ipykernel_224448\\2893921692.py:9: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  X_train = df_train.drop('label', axis=1).applymap(lambda x: complex(x)).values\n",
      "C:\\Users\\Y\\AppData\\Local\\Temp\\ipykernel_224448\\2893921692.py:14: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  X_test = df_test.drop('label', axis=1).applymap(lambda x: complex(x)).values\n"
     ]
    }
   ],
   "source": [
    "# 加载数据\n",
    "X_train, y_train = {}, {}\n",
    "X_test, y_test = {}, {}\n",
    "\n",
    "for list in snr_list:\n",
    "    # 训练集\n",
    "    df_train = shuffle(pd.read_csv(f'../preprocessed/combined_features_{list}.csv'), random_state=42)\n",
    "    y_train = df_train['label']\n",
    "    X_train = df_train.drop('label', axis=1).applymap(lambda x: complex(x)).values\n",
    "    \n",
    "    # 测试集\n",
    "    df_test = shuffle(pd.read_csv(f'../preprocessed/combined_features_{list}_test.csv'), random_state=42)\n",
    "    y_test = df_test['label']\n",
    "    X_test = df_test.drop('label', axis=1).applymap(lambda x: complex(x)).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. 创建数据加载器\n",
    "batch_size = 32\n",
    "train_loader, test_loader, (scaler_real, scaler_imag) = create_dataloaders(X_train, y_train, X_test, y_test, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. 创建模型\n",
    "num_features = X_train.shape[1]\n",
    "num_classes = len(np.unique(y_train))\n",
    "model = create_model(num_features, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "使用设备: cuda\n"
     ]
    }
   ],
   "source": [
    "# 4. 设置训练参数\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"使用设备: {device}\")\n",
    "\n",
    "# 确保模型在GPU上\n",
    "model = create_model(num_features, num_classes)\n",
    "model = model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'max', patience=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Training for list -10 ===\n",
      "Epoch 1/30: Loss=0.7448, Acc=0.5395, Best Acc=0.5395\n",
      "Epoch 2/30: Loss=0.6913, Acc=0.5805, Best Acc=0.5805\n",
      "Epoch 3/30: Loss=0.6894, Acc=0.5855, Best Acc=0.5855\n",
      "Epoch 4/30: Loss=0.6867, Acc=0.5990, Best Acc=0.5990\n",
      "Epoch 5/30: Loss=0.6869, Acc=0.5713, Best Acc=0.5990\n",
      "Epoch 6/30: Loss=0.6816, Acc=0.5597, Best Acc=0.5990\n",
      "Epoch 7/30: Loss=0.6832, Acc=0.5650, Best Acc=0.5990\n",
      "Epoch 8/30: Loss=0.6791, Acc=0.5440, Best Acc=0.5990\n",
      "Epoch 9/30: Loss=0.6679, Acc=0.6155, Best Acc=0.6155\n",
      "Epoch 10/30: Loss=0.6656, Acc=0.6258, Best Acc=0.6258\n",
      "Epoch 11/30: Loss=0.6621, Acc=0.6098, Best Acc=0.6258\n",
      "Epoch 12/30: Loss=0.6616, Acc=0.6212, Best Acc=0.6258\n",
      "Epoch 13/30: Loss=0.6592, Acc=0.6122, Best Acc=0.6258\n",
      "Epoch 14/30: Loss=0.6567, Acc=0.6250, Best Acc=0.6258\n",
      "Epoch 15/30: Loss=0.6568, Acc=0.5915, Best Acc=0.6258\n",
      "Epoch 16/30: Loss=0.6532, Acc=0.6018, Best Acc=0.6258\n",
      "Epoch 17/30: Loss=0.6544, Acc=0.6420, Best Acc=0.6420\n",
      "Epoch 18/30: Loss=0.6542, Acc=0.6368, Best Acc=0.6420\n",
      "Epoch 19/30: Loss=0.6542, Acc=0.6322, Best Acc=0.6420\n",
      "Epoch 20/30: Loss=0.6517, Acc=0.6410, Best Acc=0.6420\n",
      "Epoch 21/30: Loss=0.6523, Acc=0.6418, Best Acc=0.6420\n",
      "Epoch 22/30: Loss=0.6504, Acc=0.6440, Best Acc=0.6440\n",
      "Epoch 23/30: Loss=0.6517, Acc=0.6410, Best Acc=0.6440\n",
      "Epoch 24/30: Loss=0.6512, Acc=0.5955, Best Acc=0.6440\n",
      "Epoch 25/30: Loss=0.6507, Acc=0.6365, Best Acc=0.6440\n",
      "Epoch 26/30: Loss=0.6525, Acc=0.5913, Best Acc=0.6440\n",
      "Epoch 27/30: Loss=0.6544, Acc=0.6288, Best Acc=0.6440\n",
      "Epoch 28/30: Loss=0.6518, Acc=0.6405, Best Acc=0.6440\n",
      "Epoch 29/30: Loss=0.6522, Acc=0.6390, Best Acc=0.6440\n",
      "Epoch 30/30: Loss=0.6529, Acc=0.6402, Best Acc=0.6440\n",
      "最终最佳准确率: 0.6440\n",
      "\n",
      "=== Training for list -5 ===\n",
      "Epoch 1/30: Loss=0.6515, Acc=0.6330, Best Acc=0.6440\n",
      "Epoch 2/30: Loss=0.6539, Acc=0.6402, Best Acc=0.6440\n",
      "Epoch 3/30: Loss=0.6516, Acc=0.6425, Best Acc=0.6440\n",
      "Epoch 4/30: Loss=0.6521, Acc=0.6352, Best Acc=0.6440\n",
      "Epoch 5/30: Loss=0.6524, Acc=0.6402, Best Acc=0.6440\n",
      "Epoch 6/30: Loss=0.6518, Acc=0.6402, Best Acc=0.6440\n",
      "Epoch 7/30: Loss=0.6509, Acc=0.6400, Best Acc=0.6440\n",
      "Epoch 8/30: Loss=0.6515, Acc=0.6435, Best Acc=0.6440\n",
      "Epoch 9/30: Loss=0.6545, Acc=0.6402, Best Acc=0.6440\n",
      "Epoch 10/30: Loss=0.6545, Acc=0.6420, Best Acc=0.6440\n",
      "Epoch 11/30: Loss=0.6507, Acc=0.6410, Best Acc=0.6440\n",
      "Epoch 12/30: Loss=0.6537, Acc=0.6442, Best Acc=0.6442\n",
      "Epoch 13/30: Loss=0.6526, Acc=0.5927, Best Acc=0.6442\n",
      "Epoch 14/30: Loss=0.6529, Acc=0.6435, Best Acc=0.6442\n",
      "Epoch 15/30: Loss=0.6527, Acc=0.6252, Best Acc=0.6442\n",
      "Epoch 16/30: Loss=0.6503, Acc=0.6338, Best Acc=0.6442\n",
      "Epoch 17/30: Loss=0.6497, Acc=0.6412, Best Acc=0.6442\n",
      "Epoch 18/30: Loss=0.6510, Acc=0.6130, Best Acc=0.6442\n",
      "Epoch 19/30: Loss=0.6523, Acc=0.6400, Best Acc=0.6442\n",
      "Epoch 20/30: Loss=0.6525, Acc=0.6315, Best Acc=0.6442\n",
      "Epoch 21/30: Loss=0.6512, Acc=0.6325, Best Acc=0.6442\n",
      "Epoch 22/30: Loss=0.6537, Acc=0.6420, Best Acc=0.6442\n",
      "Epoch 23/30: Loss=0.6534, Acc=0.6402, Best Acc=0.6442\n",
      "Epoch 24/30: Loss=0.6509, Acc=0.6428, Best Acc=0.6442\n",
      "Epoch 25/30: Loss=0.6524, Acc=0.6405, Best Acc=0.6442\n",
      "Epoch 26/30: Loss=0.6541, Acc=0.6462, Best Acc=0.6462\n",
      "Epoch 27/30: Loss=0.6521, Acc=0.5965, Best Acc=0.6462\n",
      "Epoch 28/30: Loss=0.6519, Acc=0.6405, Best Acc=0.6462\n",
      "Epoch 29/30: Loss=0.6500, Acc=0.6460, Best Acc=0.6462\n",
      "Epoch 30/30: Loss=0.6519, Acc=0.6438, Best Acc=0.6462\n",
      "最终最佳准确率: 0.6462\n",
      "\n",
      "=== Training for list 0 ===\n",
      "Epoch 1/30: Loss=0.6531, Acc=0.6418, Best Acc=0.6462\n",
      "Epoch 2/30: Loss=0.6522, Acc=0.6372, Best Acc=0.6462\n",
      "Epoch 3/30: Loss=0.6507, Acc=0.6190, Best Acc=0.6462\n",
      "Epoch 4/30: Loss=0.6545, Acc=0.6422, Best Acc=0.6462\n",
      "Epoch 5/30: Loss=0.6539, Acc=0.6400, Best Acc=0.6462\n",
      "Epoch 6/30: Loss=0.6527, Acc=0.6422, Best Acc=0.6462\n",
      "Epoch 7/30: Loss=0.6535, Acc=0.6418, Best Acc=0.6462\n",
      "Epoch 8/30: Loss=0.6522, Acc=0.6310, Best Acc=0.6462\n",
      "Epoch 9/30: Loss=0.6528, Acc=0.6415, Best Acc=0.6462\n",
      "Epoch 10/30: Loss=0.6533, Acc=0.6438, Best Acc=0.6462\n",
      "Epoch 11/30: Loss=0.6546, Acc=0.6398, Best Acc=0.6462\n",
      "Epoch 12/30: Loss=0.6532, Acc=0.6412, Best Acc=0.6462\n",
      "Epoch 13/30: Loss=0.6512, Acc=0.6405, Best Acc=0.6462\n",
      "Epoch 14/30: Loss=0.6513, Acc=0.6430, Best Acc=0.6462\n",
      "Epoch 15/30: Loss=0.6510, Acc=0.6368, Best Acc=0.6462\n",
      "Epoch 16/30: Loss=0.6556, Acc=0.5863, Best Acc=0.6462\n",
      "Epoch 17/30: Loss=0.6536, Acc=0.6435, Best Acc=0.6462\n",
      "Epoch 18/30: Loss=0.6532, Acc=0.6430, Best Acc=0.6462\n",
      "Epoch 19/30: Loss=0.6518, Acc=0.6398, Best Acc=0.6462\n",
      "Epoch 20/30: Loss=0.6504, Acc=0.6298, Best Acc=0.6462\n",
      "Epoch 21/30: Loss=0.6529, Acc=0.6412, Best Acc=0.6462\n",
      "Epoch 22/30: Loss=0.6517, Acc=0.6145, Best Acc=0.6462\n",
      "Epoch 23/30: Loss=0.6526, Acc=0.6398, Best Acc=0.6462\n",
      "Epoch 24/30: Loss=0.6534, Acc=0.6348, Best Acc=0.6462\n",
      "Epoch 25/30: Loss=0.6532, Acc=0.6358, Best Acc=0.6462\n",
      "Epoch 26/30: Loss=0.6527, Acc=0.6405, Best Acc=0.6462\n",
      "Epoch 27/30: Loss=0.6519, Acc=0.6280, Best Acc=0.6462\n",
      "Epoch 28/30: Loss=0.6535, Acc=0.6415, Best Acc=0.6462\n",
      "Epoch 29/30: Loss=0.6523, Acc=0.6348, Best Acc=0.6462\n",
      "Epoch 30/30: Loss=0.6526, Acc=0.6368, Best Acc=0.6462\n",
      "最终最佳准确率: 0.6462\n",
      "\n",
      "=== Training for list 5 ===\n",
      "Epoch 1/30: Loss=0.6519, Acc=0.6282, Best Acc=0.6462\n",
      "Epoch 2/30: Loss=0.6526, Acc=0.6380, Best Acc=0.6462\n",
      "Epoch 3/30: Loss=0.6506, Acc=0.6355, Best Acc=0.6462\n",
      "Epoch 4/30: Loss=0.6538, Acc=0.6322, Best Acc=0.6462\n",
      "Epoch 5/30: Loss=0.6514, Acc=0.6368, Best Acc=0.6462\n",
      "Epoch 6/30: Loss=0.6536, Acc=0.6432, Best Acc=0.6462\n",
      "Epoch 7/30: Loss=0.6508, Acc=0.6452, Best Acc=0.6462\n",
      "Epoch 8/30: Loss=0.6512, Acc=0.6392, Best Acc=0.6462\n",
      "Epoch 9/30: Loss=0.6530, Acc=0.6360, Best Acc=0.6462\n",
      "Epoch 10/30: Loss=0.6516, Acc=0.5982, Best Acc=0.6462\n",
      "Epoch 11/30: Loss=0.6525, Acc=0.6420, Best Acc=0.6462\n",
      "Epoch 12/30: Loss=0.6536, Acc=0.6390, Best Acc=0.6462\n",
      "Epoch 13/30: Loss=0.6526, Acc=0.6400, Best Acc=0.6462\n",
      "Epoch 14/30: Loss=0.6530, Acc=0.6420, Best Acc=0.6462\n",
      "Epoch 15/30: Loss=0.6512, Acc=0.6388, Best Acc=0.6462\n",
      "Epoch 16/30: Loss=0.6526, Acc=0.6288, Best Acc=0.6462\n",
      "Epoch 17/30: Loss=0.6525, Acc=0.6415, Best Acc=0.6462\n",
      "Epoch 18/30: Loss=0.6524, Acc=0.6372, Best Acc=0.6462\n",
      "Epoch 19/30: Loss=0.6519, Acc=0.6385, Best Acc=0.6462\n",
      "Epoch 20/30: Loss=0.6509, Acc=0.6428, Best Acc=0.6462\n",
      "Epoch 21/30: Loss=0.6548, Acc=0.6418, Best Acc=0.6462\n",
      "Epoch 22/30: Loss=0.6528, Acc=0.6400, Best Acc=0.6462\n",
      "Epoch 23/30: Loss=0.6512, Acc=0.6390, Best Acc=0.6462\n",
      "Epoch 24/30: Loss=0.6502, Acc=0.6415, Best Acc=0.6462\n",
      "Epoch 25/30: Loss=0.6505, Acc=0.6410, Best Acc=0.6462\n",
      "Epoch 26/30: Loss=0.6505, Acc=0.6390, Best Acc=0.6462\n",
      "Epoch 27/30: Loss=0.6524, Acc=0.6340, Best Acc=0.6462\n",
      "Epoch 28/30: Loss=0.6502, Acc=0.6408, Best Acc=0.6462\n",
      "Epoch 29/30: Loss=0.6527, Acc=0.6450, Best Acc=0.6462\n",
      "Epoch 30/30: Loss=0.6520, Acc=0.6082, Best Acc=0.6462\n",
      "最终最佳准确率: 0.6462\n",
      "\n",
      "=== Training for list 10 ===\n",
      "Epoch 1/30: Loss=0.6538, Acc=0.6372, Best Acc=0.6462\n",
      "Epoch 2/30: Loss=0.6513, Acc=0.6400, Best Acc=0.6462\n",
      "Epoch 3/30: Loss=0.6530, Acc=0.6435, Best Acc=0.6462\n",
      "Epoch 4/30: Loss=0.6525, Acc=0.6425, Best Acc=0.6462\n",
      "Epoch 5/30: Loss=0.6542, Acc=0.6420, Best Acc=0.6462\n",
      "Epoch 6/30: Loss=0.6516, Acc=0.6358, Best Acc=0.6462\n",
      "Epoch 7/30: Loss=0.6529, Acc=0.6430, Best Acc=0.6462\n",
      "Epoch 8/30: Loss=0.6532, Acc=0.6375, Best Acc=0.6462\n",
      "Epoch 9/30: Loss=0.6505, Acc=0.6428, Best Acc=0.6462\n",
      "Epoch 10/30: Loss=0.6518, Acc=0.6398, Best Acc=0.6462\n",
      "Epoch 11/30: Loss=0.6531, Acc=0.6402, Best Acc=0.6462\n",
      "Epoch 12/30: Loss=0.6540, Acc=0.6428, Best Acc=0.6462\n",
      "Epoch 13/30: Loss=0.6521, Acc=0.6368, Best Acc=0.6462\n",
      "Epoch 14/30: Loss=0.6527, Acc=0.5903, Best Acc=0.6462\n",
      "Epoch 15/30: Loss=0.6506, Acc=0.6390, Best Acc=0.6462\n",
      "Epoch 16/30: Loss=0.6520, Acc=0.6410, Best Acc=0.6462\n",
      "Epoch 17/30: Loss=0.6530, Acc=0.6402, Best Acc=0.6462\n",
      "Epoch 18/30: Loss=0.6507, Acc=0.6405, Best Acc=0.6462\n",
      "Epoch 19/30: Loss=0.6523, Acc=0.6412, Best Acc=0.6462\n",
      "Epoch 20/30: Loss=0.6520, Acc=0.6400, Best Acc=0.6462\n",
      "Epoch 21/30: Loss=0.6524, Acc=0.6388, Best Acc=0.6462\n",
      "Epoch 22/30: Loss=0.6538, Acc=0.6345, Best Acc=0.6462\n",
      "Epoch 23/30: Loss=0.6533, Acc=0.6422, Best Acc=0.6462\n",
      "Epoch 24/30: Loss=0.6532, Acc=0.6405, Best Acc=0.6462\n",
      "Epoch 25/30: Loss=0.6515, Acc=0.6402, Best Acc=0.6462\n",
      "Epoch 26/30: Loss=0.6523, Acc=0.6388, Best Acc=0.6462\n",
      "Epoch 27/30: Loss=0.6518, Acc=0.6432, Best Acc=0.6462\n",
      "Epoch 28/30: Loss=0.6534, Acc=0.6402, Best Acc=0.6462\n",
      "Epoch 29/30: Loss=0.6500, Acc=0.6430, Best Acc=0.6462\n",
      "Epoch 30/30: Loss=0.6503, Acc=0.6405, Best Acc=0.6462\n",
      "最终最佳准确率: 0.6462\n",
      "\n",
      "=== Training for list 15 ===\n",
      "Epoch 1/30: Loss=0.6514, Acc=0.6395, Best Acc=0.6462\n",
      "Epoch 2/30: Loss=0.6524, Acc=0.6390, Best Acc=0.6462\n",
      "Epoch 3/30: Loss=0.6516, Acc=0.6408, Best Acc=0.6462\n",
      "Epoch 4/30: Loss=0.6530, Acc=0.6408, Best Acc=0.6462\n",
      "Epoch 5/30: Loss=0.6526, Acc=0.6428, Best Acc=0.6462\n",
      "Epoch 6/30: Loss=0.6559, Acc=0.6408, Best Acc=0.6462\n",
      "Epoch 7/30: Loss=0.6527, Acc=0.6332, Best Acc=0.6462\n",
      "Epoch 8/30: Loss=0.6508, Acc=0.6438, Best Acc=0.6462\n",
      "Epoch 9/30: Loss=0.6514, Acc=0.6438, Best Acc=0.6462\n",
      "Epoch 10/30: Loss=0.6511, Acc=0.6422, Best Acc=0.6462\n",
      "Epoch 11/30: Loss=0.6516, Acc=0.6402, Best Acc=0.6462\n",
      "Epoch 12/30: Loss=0.6534, Acc=0.6395, Best Acc=0.6462\n",
      "Epoch 13/30: Loss=0.6504, Acc=0.6402, Best Acc=0.6462\n",
      "Epoch 14/30: Loss=0.6502, Acc=0.6372, Best Acc=0.6462\n",
      "Epoch 15/30: Loss=0.6525, Acc=0.6180, Best Acc=0.6462\n",
      "Epoch 16/30: Loss=0.6515, Acc=0.6398, Best Acc=0.6462\n",
      "Epoch 17/30: Loss=0.6517, Acc=0.6422, Best Acc=0.6462\n",
      "Epoch 18/30: Loss=0.6528, Acc=0.6420, Best Acc=0.6462\n",
      "Epoch 19/30: Loss=0.6520, Acc=0.6420, Best Acc=0.6462\n",
      "Epoch 20/30: Loss=0.6539, Acc=0.6405, Best Acc=0.6462\n",
      "Epoch 21/30: Loss=0.6521, Acc=0.6380, Best Acc=0.6462\n",
      "Epoch 22/30: Loss=0.6501, Acc=0.6382, Best Acc=0.6462\n",
      "Epoch 23/30: Loss=0.6500, Acc=0.6375, Best Acc=0.6462\n",
      "Epoch 24/30: Loss=0.6520, Acc=0.6028, Best Acc=0.6462\n",
      "Epoch 25/30: Loss=0.6526, Acc=0.6412, Best Acc=0.6462\n",
      "Epoch 26/30: Loss=0.6496, Acc=0.6372, Best Acc=0.6462\n",
      "Epoch 27/30: Loss=0.6521, Acc=0.6385, Best Acc=0.6462\n",
      "Epoch 28/30: Loss=0.6513, Acc=0.6160, Best Acc=0.6462\n",
      "Epoch 29/30: Loss=0.6551, Acc=0.6352, Best Acc=0.6462\n",
      "Epoch 30/30: Loss=0.6516, Acc=0.6318, Best Acc=0.6462\n",
      "最终最佳准确率: 0.6462\n",
      "\n",
      "=== Training for list 20 ===\n",
      "Epoch 1/30: Loss=0.6519, Acc=0.6402, Best Acc=0.6462\n",
      "Epoch 2/30: Loss=0.6518, Acc=0.6392, Best Acc=0.6462\n",
      "Epoch 3/30: Loss=0.6516, Acc=0.6412, Best Acc=0.6462\n",
      "Epoch 4/30: Loss=0.6518, Acc=0.6402, Best Acc=0.6462\n",
      "Epoch 5/30: Loss=0.6500, Acc=0.6402, Best Acc=0.6462\n",
      "Epoch 6/30: Loss=0.6535, Acc=0.6420, Best Acc=0.6462\n",
      "Epoch 7/30: Loss=0.6532, Acc=0.6425, Best Acc=0.6462\n",
      "Epoch 8/30: Loss=0.6519, Acc=0.6395, Best Acc=0.6462\n",
      "Epoch 9/30: Loss=0.6515, Acc=0.6412, Best Acc=0.6462\n",
      "Epoch 10/30: Loss=0.6522, Acc=0.6390, Best Acc=0.6462\n",
      "Epoch 11/30: Loss=0.6542, Acc=0.6410, Best Acc=0.6462\n",
      "Epoch 12/30: Loss=0.6527, Acc=0.6160, Best Acc=0.6462\n",
      "Epoch 13/30: Loss=0.6532, Acc=0.6400, Best Acc=0.6462\n",
      "Epoch 14/30: Loss=0.6521, Acc=0.6398, Best Acc=0.6462\n",
      "Epoch 15/30: Loss=0.6528, Acc=0.6430, Best Acc=0.6462\n",
      "Epoch 16/30: Loss=0.6509, Acc=0.6418, Best Acc=0.6462\n",
      "Epoch 17/30: Loss=0.6545, Acc=0.6418, Best Acc=0.6462\n",
      "Epoch 18/30: Loss=0.6527, Acc=0.6300, Best Acc=0.6462\n",
      "Epoch 19/30: Loss=0.6536, Acc=0.6390, Best Acc=0.6462\n",
      "Epoch 20/30: Loss=0.6510, Acc=0.6435, Best Acc=0.6462\n",
      "Epoch 21/30: Loss=0.6506, Acc=0.6382, Best Acc=0.6462\n",
      "Epoch 22/30: Loss=0.6545, Acc=0.6378, Best Acc=0.6462\n",
      "Epoch 23/30: Loss=0.6519, Acc=0.6390, Best Acc=0.6462\n",
      "Epoch 24/30: Loss=0.6539, Acc=0.6320, Best Acc=0.6462\n",
      "Epoch 25/30: Loss=0.6511, Acc=0.6410, Best Acc=0.6462\n",
      "Epoch 26/30: Loss=0.6517, Acc=0.6342, Best Acc=0.6462\n",
      "Epoch 27/30: Loss=0.6519, Acc=0.6398, Best Acc=0.6462\n",
      "Epoch 28/30: Loss=0.6528, Acc=0.6398, Best Acc=0.6462\n",
      "Epoch 29/30: Loss=0.6528, Acc=0.6355, Best Acc=0.6462\n",
      "Epoch 30/30: Loss=0.6519, Acc=0.6435, Best Acc=0.6462\n",
      "最终最佳准确率: 0.6462\n",
      "\n",
      "=== Training for list 25 ===\n",
      "Epoch 1/30: Loss=0.6529, Acc=0.6368, Best Acc=0.6462\n",
      "Epoch 2/30: Loss=0.6523, Acc=0.5815, Best Acc=0.6462\n",
      "Epoch 3/30: Loss=0.6528, Acc=0.6428, Best Acc=0.6462\n",
      "Epoch 4/30: Loss=0.6538, Acc=0.6415, Best Acc=0.6462\n",
      "Epoch 5/30: Loss=0.6528, Acc=0.6192, Best Acc=0.6462\n",
      "Epoch 6/30: Loss=0.6533, Acc=0.6410, Best Acc=0.6462\n",
      "Epoch 7/30: Loss=0.6516, Acc=0.6375, Best Acc=0.6462\n",
      "Epoch 8/30: Loss=0.6517, Acc=0.6400, Best Acc=0.6462\n",
      "Epoch 9/30: Loss=0.6536, Acc=0.6388, Best Acc=0.6462\n",
      "Epoch 10/30: Loss=0.6501, Acc=0.6402, Best Acc=0.6462\n",
      "Epoch 11/30: Loss=0.6521, Acc=0.6408, Best Acc=0.6462\n",
      "Epoch 12/30: Loss=0.6515, Acc=0.6410, Best Acc=0.6462\n",
      "Epoch 13/30: Loss=0.6531, Acc=0.6398, Best Acc=0.6462\n",
      "Epoch 14/30: Loss=0.6519, Acc=0.6382, Best Acc=0.6462\n",
      "Epoch 15/30: Loss=0.6503, Acc=0.6408, Best Acc=0.6462\n",
      "Epoch 16/30: Loss=0.6521, Acc=0.6442, Best Acc=0.6462\n",
      "Epoch 17/30: Loss=0.6521, Acc=0.6370, Best Acc=0.6462\n",
      "Epoch 18/30: Loss=0.6540, Acc=0.6402, Best Acc=0.6462\n",
      "Epoch 19/30: Loss=0.6527, Acc=0.5952, Best Acc=0.6462\n",
      "Epoch 20/30: Loss=0.6509, Acc=0.6438, Best Acc=0.6462\n",
      "Epoch 21/30: Loss=0.6540, Acc=0.6428, Best Acc=0.6462\n",
      "Epoch 22/30: Loss=0.6537, Acc=0.6425, Best Acc=0.6462\n",
      "Epoch 23/30: Loss=0.6535, Acc=0.6430, Best Acc=0.6462\n",
      "Epoch 24/30: Loss=0.6528, Acc=0.6400, Best Acc=0.6462\n",
      "Epoch 25/30: Loss=0.6532, Acc=0.6000, Best Acc=0.6462\n",
      "Epoch 26/30: Loss=0.6532, Acc=0.6398, Best Acc=0.6462\n",
      "Epoch 27/30: Loss=0.6508, Acc=0.6412, Best Acc=0.6462\n",
      "Epoch 28/30: Loss=0.6520, Acc=0.6378, Best Acc=0.6462\n",
      "Epoch 29/30: Loss=0.6511, Acc=0.6352, Best Acc=0.6462\n",
      "Epoch 30/30: Loss=0.6503, Acc=0.6425, Best Acc=0.6462\n",
      "最终最佳准确率: 0.6462\n",
      "\n",
      "=== Training for list 30 ===\n",
      "Epoch 1/30: Loss=0.6502, Acc=0.6382, Best Acc=0.6462\n",
      "Epoch 2/30: Loss=0.6502, Acc=0.6442, Best Acc=0.6462\n",
      "Epoch 3/30: Loss=0.6529, Acc=0.6390, Best Acc=0.6462\n",
      "Epoch 4/30: Loss=0.6510, Acc=0.6428, Best Acc=0.6462\n",
      "Epoch 5/30: Loss=0.6528, Acc=0.6402, Best Acc=0.6462\n",
      "Epoch 6/30: Loss=0.6535, Acc=0.6385, Best Acc=0.6462\n",
      "Epoch 7/30: Loss=0.6496, Acc=0.6378, Best Acc=0.6462\n",
      "Epoch 8/30: Loss=0.6516, Acc=0.6425, Best Acc=0.6462\n",
      "Epoch 9/30: Loss=0.6523, Acc=0.6422, Best Acc=0.6462\n",
      "Epoch 10/30: Loss=0.6546, Acc=0.6410, Best Acc=0.6462\n",
      "Epoch 11/30: Loss=0.6527, Acc=0.6235, Best Acc=0.6462\n",
      "Epoch 12/30: Loss=0.6509, Acc=0.6412, Best Acc=0.6462\n",
      "Epoch 13/30: Loss=0.6543, Acc=0.6425, Best Acc=0.6462\n",
      "Epoch 14/30: Loss=0.6530, Acc=0.6412, Best Acc=0.6462\n",
      "Epoch 15/30: Loss=0.6528, Acc=0.6335, Best Acc=0.6462\n",
      "Epoch 16/30: Loss=0.6516, Acc=0.6412, Best Acc=0.6462\n",
      "Epoch 17/30: Loss=0.6533, Acc=0.6422, Best Acc=0.6462\n",
      "Epoch 18/30: Loss=0.6498, Acc=0.6392, Best Acc=0.6462\n",
      "Epoch 19/30: Loss=0.6508, Acc=0.6400, Best Acc=0.6462\n",
      "Epoch 20/30: Loss=0.6528, Acc=0.6425, Best Acc=0.6462\n",
      "Epoch 21/30: Loss=0.6536, Acc=0.6298, Best Acc=0.6462\n",
      "Epoch 22/30: Loss=0.6516, Acc=0.6405, Best Acc=0.6462\n",
      "Epoch 23/30: Loss=0.6540, Acc=0.6405, Best Acc=0.6462\n",
      "Epoch 24/30: Loss=0.6522, Acc=0.6232, Best Acc=0.6462\n",
      "Epoch 25/30: Loss=0.6507, Acc=0.6400, Best Acc=0.6462\n",
      "Epoch 26/30: Loss=0.6531, Acc=0.6402, Best Acc=0.6462\n",
      "Epoch 27/30: Loss=0.6508, Acc=0.6388, Best Acc=0.6462\n",
      "Epoch 28/30: Loss=0.6527, Acc=0.6390, Best Acc=0.6462\n",
      "Epoch 29/30: Loss=0.6510, Acc=0.6385, Best Acc=0.6462\n",
      "Epoch 30/30: Loss=0.6523, Acc=0.6410, Best Acc=0.6462\n",
      "最终最佳准确率: 0.6462\n",
      "\n",
      "=== Training for list 35 ===\n",
      "Epoch 1/30: Loss=0.6536, Acc=0.6215, Best Acc=0.6462\n",
      "Epoch 2/30: Loss=0.6523, Acc=0.6370, Best Acc=0.6462\n",
      "Epoch 3/30: Loss=0.6541, Acc=0.6385, Best Acc=0.6462\n",
      "Epoch 4/30: Loss=0.6518, Acc=0.6388, Best Acc=0.6462\n",
      "Epoch 5/30: Loss=0.6520, Acc=0.6425, Best Acc=0.6462\n",
      "Epoch 6/30: Loss=0.6512, Acc=0.6412, Best Acc=0.6462\n",
      "Epoch 7/30: Loss=0.6510, Acc=0.6418, Best Acc=0.6462\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 19\u001b[0m\n\u001b[0;32m     16\u001b[0m x, y \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mto(device), y\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     18\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m---> 19\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     20\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, y)\n\u001b[0;32m     21\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[1;32md:\\Anaconda3\\envs\\bt\\lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\Anaconda3\\envs\\bt\\lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mf:\\Bluetooth-RF-Fingerprint\\model\\network.py:161\u001b[0m, in \u001b[0;36mComplexCNN.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    159\u001b[0m \u001b[38;5;66;03m# 残差块\u001b[39;00m\n\u001b[0;32m    160\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mres_block1(x)\n\u001b[1;32m--> 161\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mres_block2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    162\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mres_block3(x)\n\u001b[0;32m    164\u001b[0m \u001b[38;5;66;03m# 全局池化\u001b[39;00m\n",
      "File \u001b[1;32md:\\Anaconda3\\envs\\bt\\lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\Anaconda3\\envs\\bt\\lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mf:\\Bluetooth-RF-Fingerprint\\model\\network.py:109\u001b[0m, in \u001b[0;36mResidualBlock.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    107\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv1(x)\n\u001b[0;32m    108\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn1(out)\n\u001b[1;32m--> 109\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodrelu1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    110\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(out)\n\u001b[0;32m    112\u001b[0m \u001b[38;5;66;03m# 残差连接\u001b[39;00m\n",
      "File \u001b[1;32md:\\Anaconda3\\envs\\bt\\lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\Anaconda3\\envs\\bt\\lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mf:\\Bluetooth-RF-Fingerprint\\model\\network.py:68\u001b[0m, in \u001b[0;36mModReLU.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     65\u001b[0m imag \u001b[38;5;241m=\u001b[39m x[:, x\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m2\u001b[39m:]\n\u001b[0;32m     67\u001b[0m \u001b[38;5;66;03m# 计算模值\u001b[39;00m\n\u001b[1;32m---> 68\u001b[0m magnitude \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msqrt(\u001b[43mreal\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m \u001b[38;5;241m+\u001b[39m imag\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1e-5\u001b[39m)\n\u001b[0;32m     70\u001b[0m \u001b[38;5;66;03m# 应用偏置\u001b[39;00m\n\u001b[0;32m     71\u001b[0m bias_view \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32md:\\Anaconda3\\envs\\bt\\lib\\site-packages\\torch\\_tensor.py:39\u001b[0m, in \u001b[0;36m_handle_torch_function_and_wrap_type_error_to_not_implemented.<locals>.wrapped\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     37\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m has_torch_function(args):\n\u001b[0;32m     38\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(wrapped, args, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m---> 39\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m     41\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 5. 训练模型\n",
    "num_epochs = 30\n",
    "best_acc = 0.0\n",
    "\n",
    "accuracies = []\n",
    "\n",
    "\n",
    "for list in snr_list:\n",
    "    print(f\"\\n=== Training for list {list} ===\")\n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        # 训练阶段\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        \n",
    "        for x, y in train_loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(x)\n",
    "            loss = criterion(outputs, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "        \n",
    "        # 验证阶段\n",
    "        model.eval()\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        all_preds = []\n",
    "        all_labels = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for x, y in test_loader:\n",
    "                x, y = x.to(device), y.to(device)\n",
    "                outputs = model(x)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += y.size(0)\n",
    "                correct += (predicted == y).sum().item()\n",
    "                all_preds.extend(predicted.cpu().numpy())\n",
    "                all_labels.extend(y.cpu().numpy())\n",
    "        \n",
    "        acc = correct / total\n",
    "        scheduler.step(acc)\n",
    "        \n",
    "        if acc > best_acc:\n",
    "            best_acc = acc\n",
    "            # 保存最佳模型\n",
    "            # torch.save(model.state_dict(), f'./model_save/ComplexCNN_{list}.pth')\n",
    "        \n",
    "        print(f'Epoch {epoch}/{num_epochs}: Loss={total_loss/len(train_loader):.4f}, Acc={acc:.4f}, Best Acc={best_acc:.4f}')\n",
    "\n",
    "    print(f\"最终最佳准确率: {best_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. 绘制混淆矩阵（可选）\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.title('混淆矩阵', fontproperties=\"SimSun\")\n",
    "plt.ylabel('真实类别', fontproperties=\"SimSun\")\n",
    "plt.xlabel('预测类别', fontproperties=\"SimSun\")\n",
    "plt.xticks(range(4), ['bladerf', 'hackrf0', 'hackrf1', 'limesdr'])\n",
    "plt.yticks(range(4), ['bladerf', 'hackrf0', 'hackrf1', 'limesdr'])\n",
    "plt.savefig(f'./img/confusion_matrix_{list}.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
