{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "import xgboost as xgb\n",
    "import catboost as cb\n",
    "import lightgbm as lgb\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义文件序号列表\n",
    "sizes = [128, 256, 512, 1024, 2048, 4096]\n",
    "snr_list = [-10, -5, 0, 5, 10, 15, 20, 25, 30, 35, 40, 45, 50]\n",
    "# 初始化字典存储每个算法的准确度\n",
    "accuracies = {alg: [] for alg in ['XGBoost', 'LightGBM', 'CatBoost', 'GBDT', 'RF', 'DT', 'SVM', 'Naive Bayes', 'KNN']}\n",
    "# 定义每个算法的模型实例\n",
    "models = {\n",
    "    'XGBoost': xgb.XGBClassifier(eval_metric='logloss'),\n",
    "    'LightGBM': lgb.LGBMClassifier(verbose=0, force_row_wise=True),\n",
    "    'CatBoost': cb.CatBoostClassifier(verbose=0),\n",
    "    'GBDT': GradientBoostingClassifier(),\n",
    "    'RF': RandomForestClassifier(),\n",
    "    'DT': DecisionTreeClassifier(),\n",
    "    'SVM': SVC(kernel=\"linear\", decision_function_shape=\"ovo\", max_iter=100000),\n",
    "    'Naive Bayes': GaussianNB(),\n",
    "    'KNN': KNeighborsClassifier(n_neighbors=5, weights='distance', algorithm='kd_tree', leaf_size=10, p=1, n_jobs=-1)\n",
    "}\n",
    "# 定义标识点\n",
    "markers = {\n",
    "    'XGBoost': 'o',  # 圆圈\n",
    "    'LightGBM': 'D',  # 菱形\n",
    "    'CatBoost': 's',  # 方块\n",
    "    'GBDT': 'p',  # 五角星\n",
    "    'RF': 'v',  # 下三角\n",
    "    'DT': '*',\n",
    "    'SVM': '>',  # 右三角\n",
    "    'Naive Bayes': '<',  # 左三角\n",
    "    'KNN': '^'  # 上三角\n",
    "}\n",
    "file_path_train = []\n",
    "file_path_test  = []\n",
    "# 循环遍历每个文件序号，并加载相应的 CSV 文件\n",
    "for snr in snr_list:\n",
    "    file_path_train.append(f'../preprocessed/combined_features_{snr}.csv')\n",
    "    file_path_test.append(f'../preprocessed/combined_features_{snr}_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 初始化字典存储X_train和y_train数据集\n",
    "X_trains = {}\n",
    "y_trains = {}\n",
    "X_tests = {}\n",
    "y_tests = {}\n",
    "# 循环处理每个文件\n",
    "for snr, file_path in zip(snr_list, file_path_train):\n",
    "    # 读取数据集\n",
    "    df = pd.read_csv(file_path)\n",
    "    # 打乱数据集\n",
    "    df = shuffle(df, random_state=42)\n",
    "    # 分离标签和特征\n",
    "    y_trains[snr] = df['label']\n",
    "    X_trains[snr] = df.drop('label', axis=1)\n",
    "for snr, file_path in zip(snr_list, file_path_test):\n",
    "    # 读取数据集\n",
    "    df = pd.read_csv(file_path)\n",
    "    # 打乱数据集\n",
    "    df = shuffle(df, random_state=42)\n",
    "    # 分离标签和特征\n",
    "    y_tests[snr] = df['label']\n",
    "    X_tests[snr] = df.drop('label', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练模型并评估准确度\n",
    "for snr in snr_list:\n",
    "    X_train = X_trains[snr]\n",
    "    X_test  = X_tests [snr]\n",
    "    y_train = y_trains[snr]\n",
    "    y_test  = y_tests [snr]\n",
    "    # print(f\"Results for data snr {snr}:\")\n",
    "    for alg, model in models.items():\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        accuracies[alg].append(accuracy)\n",
    "        # print(f\"{alg}: Accuracy = {accuracy:.4f}\")\n",
    "# accuracies.sort()\n",
    "\n",
    "# 绘制不同算法在不同数据集大小上的准确率\n",
    "# plt.figure(figsize=(30, 15))\n",
    "# for alg, acc_list in accuracies.items():\n",
    "#     plt.plot(snr_list, acc_list, label=alg, marker=markers[alg])\n",
    "# plt.title('Comparison of Different ML Algorithms')\n",
    "# plt.xlabel('Training Set SNR')\n",
    "# plt.ylabel('Classification Accuracy')\n",
    "# plt.legend()\n",
    "# plt.grid(True)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 绘制不同算法在不同数据集大小上的准确率\n",
    "for alg, acc_list in accuracies.items():\n",
    "    plt.plot(snr_list, acc_list, label=alg, marker=markers[alg])\n",
    "plt.xlabel('信噪比/dB', fontproperties=\"SimSun\")\n",
    "plt.ylabel('分类准确率', fontproperties=\"SimSun\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.savefig('snr.png',dpi=600, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 打印结果\n",
    "# for size in sorted(results):\n",
    "#     print(f\"\\nResults for data size {size}:\")\n",
    "#     for alg in sorted(results[size]):\n",
    "#         print(f\"  {alg}: Accuracy = {results[size][alg]:.4f}\")\n",
    "\n",
    "for alg, acc in accuracies.items():\n",
    "    print(alg, str(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = {alg: [] for alg in ['XGBoost', 'LightGBM', 'CatBoost', 'GBDT', 'RF', 'DT', 'SVM', 'Naive Bayes', 'KNN']}\n",
    "acc['XGBoost']=[0.27225, 0.2855, 0.273, 0.308, 0.374, 0.475, 0.5795, 0.65425, 0.72, 0.8, 0.86, 0.9045, 0.92675]\n",
    "acc['LightGBM']=[0.27925, 0.27625, 0.2955, 0.323, 0.37825, 0.4795, 0.57475, 0.65975, 0.72425, 0.8025, 0.8615, 0.905, 0.922]\n",
    "acc['CatBoost']=[0.2655, 0.27675, 0.28425, 0.3215, 0.39575, 0.48225, 0.5875, 0.664, 0.7305, 0.80125, 0.86675, 0.907, 0.919]\n",
    "acc['GBDT']=[0.271, 0.2895, 0.3025, 0.31525, 0.36375, 0.45875, 0.56525, 0.64325, 0.7025, 0.78625, 0.83975, 0.87875, 0.90025]\n",
    "acc['RF']=[0.271, 0.27475, 0.27675, 0.31125, 0.35975, 0.46675, 0.56075, 0.655, 0.722, 0.80075, 0.86325, 0.9025, 0.92075]\n",
    "acc['DT']=[0.25775, 0.25775, 0.25475, 0.28075, 0.2895, 0.39625, 0.5055, 0.55575, 0.6425, 0.72925, 0.7925, 0.8435, 0.8705]\n",
    "acc['SVM']=[0.256, 0.268, 0.2965, 0.29725, 0.28875, 0.3165, 0.3015, 0.33275, 0.2925, 0.32075, 0.32375, 0.3185, 0.361]\n",
    "acc['Naive Bayes']=[0.27775, 0.29675, 0.2955, 0.29275, 0.29925, 0.30775, 0.30425, 0.333, 0.48175, 0.55475, 0.57025, 0.617, 0.625]\n",
    "acc['KNN']=[0.24375, 0.259, 0.25625, 0.273, 0.28375, 0.306, 0.354, 0.39875, 0.44775, 0.481, 0.5045, 0.5155, 0.52775]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 绘制不同算法在不同数据集大小上的准确率\n",
    "for alg, acc_list in acc.items():\n",
    "    plt.plot(snr_list, acc_list, label=alg, marker=markers[alg])\n",
    "plt.xlabel('信噪比/dB', fontproperties=\"SimSun\",size=14)\n",
    "plt.ylabel('分类准确率', fontproperties=\"SimSun\",size=14)\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.savefig('./img/snr_new.png',dpi=600, bbox_inches='tight')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
