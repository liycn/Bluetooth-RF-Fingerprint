{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from network import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在处理 bladerf 的数据...✅处理完成，获取了 48828 个样本\n",
      "正在处理 hackrf0 的数据...✅处理完成，获取了 48828 个样本\n",
      "正在处理 hackrf1 的数据...✅处理完成，获取了 48828 个样本\n",
      "正在处理 limesdr 的数据...✅处理完成，获取了 48828 个样本\n"
     ]
    }
   ],
   "source": [
    "# 读取所有设备的IQ数据\n",
    "device_files = {\n",
    "    \"bladerf\": \"../dataset/raw data/bladerf/bladerf.iq\",\n",
    "    \"hackrf0\": \"../dataset/raw data/hackrf0/hackrf0.iq\",\n",
    "    \"hackrf1\": \"../dataset/raw data/hackrf1/hackrf1.iq\",\n",
    "    \"limesdr\": \"../dataset/raw data/limesdr/limesdr.iq\"\n",
    "}\n",
    "\n",
    "all_data = []\n",
    "all_labels = []\n",
    "\n",
    "for label_idx, (device_name, file_path) in enumerate(device_files.items()):\n",
    "    print(f\"正在处理 {device_name} 的数据...\",end=\"\")\n",
    "    # 读取数据\n",
    "    data = load_iq_file(file_path)\n",
    "    \n",
    "    # 分段数据（将连续IQ数据分成固定长度的片段）\n",
    "    segment_length = 1024  # 每个样本的IQ点数，根据需要调整\n",
    "    num_segments = len(data) // segment_length\n",
    "    segments = data[:num_segments * segment_length].reshape(num_segments, segment_length)\n",
    "    \n",
    "    # 添加到数据集\n",
    "    all_data.append(segments)\n",
    "    all_labels.append(np.full(num_segments, label_idx))\n",
    "    \n",
    "    print(f\"✅处理完成，获取了 {num_segments} 个样本\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集样本数: 156249\n",
      "测试集样本数: 39063\n"
     ]
    }
   ],
   "source": [
    "# 合并数据\n",
    "X = np.vstack(all_data)\n",
    "y = np.concatenate(all_labels)\n",
    "\n",
    "# 分割为训练集和测试集\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "print(f\"训练集样本数: {len(X_train)}\")\n",
    "print(f\"测试集样本数: {len(X_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建数据加载器\n",
    "batch_size = 32\n",
    "train_loader, test_loader, scalers = create_dataloaders(\n",
    "    X_train, y_train, X_test, y_test, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 初始化模型\n",
    "num_features = X_train.shape[1]  # 每个样本的IQ点数\n",
    "num_classes = 4  # bladerf, hackrf0, hackrf1, limesdr\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = create_model(num_features, num_classes).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载之前训练好的模型参数（如果有）\n",
    "# model.load_state_dict(torch.load('complex_cnn_model.pth'))\n",
    "\n",
    "# 训练模型并记录准确率\n",
    "train_accuracies, test_accuracies = train_and_evaluate(model, train_loader, test_loader, device)\n",
    "\n",
    "# 保存模型\n",
    "torch.save(model.state_dict(), './models/complex_cnn_model_2.pth')\n",
    "\n",
    "# 保存标准化器\n",
    "torch.save(scalers, './models/scalers2.pth')\n",
    "\n",
    " # 获取测试集上的预测结果\n",
    "y_pred, y_true = get_predictions(model, test_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # 绘制混淆矩阵\n",
    "class_names = ['BladeRF', 'HackRF0', 'HackRF1', 'LimeSDR']\n",
    "plot_confusion_matrix(y_true, y_pred, class_names)\n",
    "\n",
    "# 绘制准确率曲线\n",
    "plot_accuracy_curve(train_accuracies, test_accuracies)\n",
    "\n",
    "# 计算总体准确率\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "print(f\"总体准确率: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 定义损失函数和优化器\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 训练循环\n",
    "# num_epochs = 30\n",
    "# for epoch in range(num_epochs):\n",
    "#     # 训练\n",
    "#     model.train()\n",
    "#     train_loss = 0\n",
    "#     correct = 0\n",
    "#     total = 0\n",
    "    \n",
    "#     for inputs, labels in train_loader:\n",
    "#         inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "#         optimizer.zero_grad()\n",
    "#         outputs = model(inputs)\n",
    "#         loss = criterion(outputs, labels)\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "        \n",
    "#         train_loss += loss.item()\n",
    "#         _, predicted = outputs.max(1)\n",
    "#         total += labels.size(0)\n",
    "#         correct += predicted.eq(labels).sum().item()\n",
    "#         # print(inputs,labels)\n",
    "    \n",
    "#     print(f'第 {epoch+1}/{num_epochs} 轮, 损失: {train_loss/len(train_loader):.4f}, 准确率: {100.*correct/total:.2f}%')\n",
    "    \n",
    "#     # 验证\n",
    "#     model.eval()\n",
    "#     test_loss = 0\n",
    "#     correct = 0\n",
    "#     total = 0\n",
    "    \n",
    "#     with torch.no_grad():\n",
    "#         for inputs, labels in test_loader:\n",
    "#             inputs, labels = inputs.to(device), labels.to(device)\n",
    "#             outputs = model(inputs)\n",
    "#             loss = criterion(outputs, labels)\n",
    "            \n",
    "#             test_loss += loss.item()\n",
    "#             _, predicted = outputs.max(1)\n",
    "#             total += labels.size(0)\n",
    "#             correct += predicted.eq(labels).sum().item()\n",
    "    \n",
    "#     print(f'测试损失: {test_loss/len(test_loader):.4f}, 测试准确率: {100.*correct/total:.2f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存模型\n",
    "torch.save(model.state_dict(), './models/complex_cnn_model.pth')\n",
    "\n",
    "torch.save(scalers, './models/scalers.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_device_with_unknown_detection(model, iq_file_path, scalers, device, confidence_threshold=0.7):\n",
    "    \"\"\"预测设备类型，包含未知设备检测\"\"\"\n",
    "    # 读取数据\n",
    "    data = load_iq_file(iq_file_path)\n",
    "    \n",
    "    # 分段数据\n",
    "    segment_length = 1024  # 与训练时相同\n",
    "    num_segments = len(data) // segment_length\n",
    "    segments = data[:num_segments * segment_length].reshape(num_segments, segment_length)\n",
    "    \n",
    "    # 创建数据集和加载器\n",
    "    dataset = ComplexSignalDataset(segments, np.zeros(len(segments)), scalers[0], scalers[1])\n",
    "    dataloader = DataLoader(dataset, batch_size=32, shuffle=False)\n",
    "    \n",
    "    # 预测\n",
    "    model.eval()\n",
    "    all_probs = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, _ in dataloader:\n",
    "            inputs = inputs.to(device)\n",
    "            outputs = model(inputs)\n",
    "            probs = F.softmax(outputs, dim=1)\n",
    "            all_probs.append(probs.cpu().numpy())\n",
    "    \n",
    "    all_probs = np.vstack(all_probs)\n",
    "    \n",
    "    # 获取最高概率及其对应的类别\n",
    "    max_probs = np.max(all_probs, axis=1)\n",
    "    predictions = np.argmax(all_probs, axis=1)\n",
    "    \n",
    "    # 计算每个段的平均置信度\n",
    "    avg_confidence = np.mean(max_probs)\n",
    "    \n",
    "    # 统计各类别的数量\n",
    "    unique, counts = np.unique(predictions, return_counts=True)\n",
    "    result = dict(zip(unique, counts))\n",
    "    \n",
    "    # 映射到设备名称\n",
    "    device_names = ['bladerf', 'hackrf0', 'hackrf1', 'limesdr']\n",
    "    final_result = {device_names[int(k)]: v for k, v in result.items()}\n",
    "    \n",
    "    # 判断是否为未知设备\n",
    "    if avg_confidence < confidence_threshold:\n",
    "        return \"未知设备\", final_result, avg_confidence\n",
    "    else:\n",
    "        # 返回出现最多的设备类型\n",
    "        majority_device = max(final_result, key=final_result.get)\n",
    "        return majority_device, final_result, avg_confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载模型和标准化器\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "num_features = 1024  # 与训练时相同\n",
    "num_classes = 4  # 四种已知设备\n",
    "model = create_model(num_features, num_classes).to(device)\n",
    "model.load_state_dict(torch.load('./models/complex_cnn_model.pth'))\n",
    "scalers = torch.load('./models/scalers.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用模型预测未知设备\n",
    "unknown_file = \"../dataset/raw data/bladerf/bladerf.iq\"\n",
    "device_type, class_counts, confidence = predict_device_with_unknown_detection(\n",
    "    model, unknown_file, scalers, device, confidence_threshold=0.7)\n",
    "\n",
    "print(f\"预测的设备类型: {device_type}\")\n",
    "print(f\"各类别的预测数量: {class_counts}\")\n",
    "print(f\"平均置信度: {confidence:.4f}\")\n",
    "\n",
    "# 如果是已知设备，可以进一步分析\n",
    "if device_type != \"未知设备\":\n",
    "    print(f\"这是一个已知设备: {device_type}\")\n",
    "else:\n",
    "    print(\"这可能是一个训练数据中未包含的设备！\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
